{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from functools import partial\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, reduce\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed_value = 2021   # 设定随机数种子\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)  # 为了禁止hash随机化，使得实验可复现。\n",
    "\n",
    "torch.manual_seed(seed_value)     # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed_value)      # 为当前GPU设置随机种子（只用一块GPU）\n",
    "torch.cuda.manual_seed_all(seed_value)   # 为所有GPU设置随机种子（多块GPU）\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def identity(t, *args, **kwargs):\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small helper modules\n",
    "#残差链接块\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "#使用最近邻方法上采样\n",
    "def Upsample(dim, dim_out = None):\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
    "        nn.Conv1d(dim, default(dim_out, dim), 3, padding = 1)\n",
    "    )\n",
    "#用卷积层下采样\n",
    "def Downsample(dim, dim_out = None):\n",
    "    return nn.Conv1d(dim, default(dim_out, dim), 4, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回一个参数标准化的卷积层\n",
    "class WeightStandardizedConv2d(nn.Conv1d):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1903.10520\n",
    "    weight standardization purportedly works synergistically with group normalization\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "\n",
    "        weight = self.weight\n",
    "        mean = reduce(weight, 'o ... -> o 1 1', 'mean')\n",
    "        var = reduce(weight, 'o ... -> o 1 1', partial(torch.var, unbiased = False))\n",
    "        normalized_weight = (weight - mean) * (var + eps).rsqrt()\n",
    "\n",
    "        return F.conv1d(x, normalized_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "#返回一个参数标准化的线性层\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
    "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
    "        return (x - mean) * (var + eps).rsqrt() * self.g\n",
    "\n",
    "#返回一个参数标准化的线性层\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "# sinusoidal positional embeds\n",
    "#返回时间序列的位置编码\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=SinusoidalPosEmb(64)\n",
    "b=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "a(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# building block modules\n",
    "#dim_out需要能够整除groups\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv1d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Block(1,8)\n",
    "x=torch.randn(64,1,50)\n",
    "a(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim = None, groups = 8):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, dim_out * 2)\n",
    "        ) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
    "        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb = None):\n",
    "\n",
    "        scale_shift = None\n",
    "        if exists(self.mlp) and exists(time_emb):\n",
    "            time_emb = self.mlp(time_emb)\n",
    "            time_emb = rearrange(time_emb, 'b c -> b c 1')\n",
    "            #.chunk在给定维度(轴)上将输入张量进行分块儿\n",
    "            scale_shift = time_emb.chunk(2, dim = 1)\n",
    "\n",
    "        h = self.block1(x, scale_shift = scale_shift)\n",
    "\n",
    "        h = self.block2(h)\n",
    "\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "\n",
    "        self.to_qkv = nn.Conv1d(dim, hidden_dim * 3, 1, bias = False)\n",
    "        self.to_out = nn.Conv1d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, n = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) n -> b h c n', h = self.heads), qkv)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b (h d) n')\n",
    "        return self.to_out(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Unet1D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        #表示模型中的隐藏维度大小\n",
    "        dim,\n",
    "        #表示输入经过初始卷积后的通道数\n",
    "        init_dim = None,\n",
    "        #表示模型输出的通道数\n",
    "        out_dim = None,\n",
    "        #表示每个下采样阶段的通道数倍增率\n",
    "        dim_mults=(1, 2, 2),\n",
    "        #表示输入数据的通道数\n",
    "        channels = 3,\n",
    "        #用来做group——norm\n",
    "        resnet_block_groups = 8\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        input_channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim)\n",
    "        self.init_conv = nn.Conv1d(input_channels, init_dim, 7, padding = 3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "\n",
    "        # time embeddings\n",
    "\n",
    "        time_dim = dim * 4\n",
    "\n",
    "        sinu_pos_emb = SinusoidalPosEmb(dim)\n",
    "        fourier_dim = dim\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(fourier_dim, time_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_in, Attention(dim_in))),\n",
    "                Downsample(dim_in, dim_out) if not is_last else nn.Conv1d(dim_in, dim_out, 3, padding = 1)\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_out, Attention(dim_out))),\n",
    "                Upsample(dim_out, dim_in) if not is_last else  nn.Conv1d(dim_out, dim_in, 3, padding = 1)\n",
    "            ]))\n",
    "\n",
    "        default_out_dim = channels \n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "\n",
    "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim = time_dim)\n",
    "        self.final_conv = nn.Conv1d(dim, self.out_dim, 1)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        r = x.clone()\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "        \n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block1(x, t)\n",
    "\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = torch.cat((x, r), dim = 1)\n",
    "\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判别器\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        #表示模型中的隐藏维度大小\n",
    "        dim,\n",
    "        #表示输入经过初始卷积后的通道数\n",
    "        init_dim = None,\n",
    "        #表示每个下采样阶段的通道数倍增率\n",
    "        dim_mults=(1,2,2),\n",
    "        #表示输入数据的通道数\n",
    "        channels = 3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "        input_channels = channels\n",
    "\n",
    "        init_dim = default(init_dim, dim)\n",
    "        self.init_conv = nn.Conv1d(input_channels, init_dim, 1)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        # time embeddings\n",
    "        time_dim = dim * 4\n",
    "\n",
    "        sinu_pos_emb = SinusoidalPosEmb(dim)\n",
    "        fourier_dim = dim\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(fourier_dim, time_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                ResnetBlock(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                Downsample(dim_in, dim_out) if not is_last else nn.Conv1d(dim_in, dim_out, 3, padding = 1)\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(mid_dim*14, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "        t = self.time_mlp(time)\n",
    "        for block1,downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x=self.fc(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Discriminator(dim=32,channels=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(128,1,56)\n",
    "model=Discriminator(dim=32,channels=1)\n",
    "x=model(x,torch.randn(128))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#设置一些超参数t，α，β\n",
    "num_steps = 100\n",
    "#制定每一步的beta，beta按照时间从小到大变化\n",
    "# scale = 1000 / num_steps\n",
    "# beta_start = scale * 0.0001\n",
    "# beta_end = scale * 0.02\n",
    "#betas = torch.linspace(beta_start,beta_end,num_steps)  # 使用linespace指定bata的值，也可以用其他方法\n",
    "betas = torch.linspace(-6, 6, num_steps)\n",
    "betas = torch.sigmoid(betas) * (0.5e-2 - 1e-5) + 1e-5\n",
    "\n",
    "alphas = 1-betas\n",
    "#累计乘法\n",
    "alphas_prod = torch.cumprod(alphas,0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "\n",
    "#为了计算t-1\n",
    "#alphas_bar_sqrt最后拼接一个1\n",
    "alphas_bar_sqrt = torch.cat([alphas_bar_sqrt,torch.ones(1)])\n",
    "#one_minus_alphas_bar_sqrt最后拼接一个0\n",
    "one_minus_alphas_bar_sqrt = torch.cat([one_minus_alphas_bar_sqrt,torch.zeros(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_sample——根据预测出来的噪声的均值以及方差计算当前时刻的数据分布\n",
    "def p_sample(model, x, t, betas, one_minus_alphas_bar_sqrt,device):\n",
    "    \"\"\"从x[T]采样t时刻的重构值\"\"\"\n",
    "    model=model.to(device)\n",
    "    t = torch.tensor([t]).to(device)\n",
    "\n",
    "    coeff = (betas[t] / one_minus_alphas_bar_sqrt[t]).to(device)\n",
    "\n",
    "    eps_theta = model(x, t)\n",
    "    #得到均值\n",
    "    mean = (1 / (1 - betas[t]).sqrt().to(device)) * (x - (coeff * eps_theta))\n",
    "\n",
    "    z = torch.randn_like(x).to(device)\n",
    "    sigma_t = betas[t].sqrt().to(device)\n",
    "    #得到sample的分布\n",
    "    sample = mean + sigma_t * z\n",
    "\n",
    "    return (sample)\n",
    "\n",
    "#从xt恢复x0\n",
    "def p_sample_loop(model, shape, n_steps, betas, one_minus_alphas_bar_sqrt,device):\n",
    "    \"\"\"从x[T]恢复x[T-1]、x[T-2]|...x[0]\"\"\"\n",
    "    cur_x = torch.randn(shape).to(device)\n",
    "    x_seq = [cur_x]\n",
    "    # 返回一个反转的迭代器\n",
    "    for i in reversed(range(n_steps)):\n",
    "        cur_x = p_sample(model, cur_x, i, betas, one_minus_alphas_bar_sqrt,device)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difussion损失函数\n",
    "def diffusion_loss_fn(model, x_0, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, n_steps):\n",
    "    \"\"\"对任意时刻t进行采样计算loss\"\"\"\n",
    "    device=x_0.device\n",
    "    batch_size = x_0.shape[0]\n",
    "\n",
    "    # 对一个batchsize样本生成随机的时刻t，t变得随机分散一些，一个batch size里面覆盖更多的t\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2,))\n",
    "    t = torch.cat([t, n_steps - 1 - t], dim=0)# t的形状（bz）\n",
    "    t = t.unsqueeze(-1).unsqueeze(-1)# t的形状（batch_size,1）\n",
    "    t_minus_1 = t - 1\n",
    "\n",
    "    # 生成随机噪音eps\n",
    "    e = torch.randn_like(x_0).to(device)\n",
    "\n",
    "    # x0的系数，根号下(alpha_bar_t)\n",
    "    a = alphas_bar_sqrt[t].to(device)\n",
    "    # eps的系数,根号下(1-alpha_bar_t)\n",
    "    aml = one_minus_alphas_bar_sqrt[t].to(device)\n",
    "    # 构造模型的输入\n",
    "    #得到xt时刻的加噪图像\n",
    "\n",
    "    x = x_0 * a + e * aml\n",
    "\n",
    "    #当t-1=-1时，x_0的系数为1，eps的系数为0，当t-1!=0时，x_0的系数为根号下(alpha_bar_t-1)，eps的系数为根号下(1-alpha_bar_t-1)\n",
    "    a_1 = alphas_bar_sqrt[t_minus_1].to(device)\n",
    "    aml_1 = one_minus_alphas_bar_sqrt[t_minus_1].to(device)\n",
    "    #得到xt-1时刻的加噪图像\n",
    "    x_t_minus_1 = x_0 * a_1 + e * aml_1\n",
    "\n",
    "\n",
    "    #t=t.squeeze(-1).squeeze(-1)\n",
    "    # 送入模型，得到t时刻的随机噪声预测值\n",
    "    output = model(x, t.squeeze(-1).squeeze(-1).to(device))\n",
    "\n",
    "    # 与真实噪声一起计算误差，求平均值\n",
    "    #返回损失，模型输出的噪声，t时刻加噪的x，t-1时刻加噪的x，以及时间t\n",
    "    return F.mse_loss(e,output),output,x,x_t_minus_1,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=False\n",
    "#选择填充方式pad_0或者interp\n",
    "pad_pattern='pad_0'\n",
    "\n",
    "if norm:\n",
    "    data = pd.read_csv('./data/'+pad_pattern+'/generate_norm.csv')\n",
    "else:\n",
    "    data = pd.read_csv('./data/'+pad_pattern+'/generate.csv')\n",
    "\n",
    "array = np.array(data)\n",
    "# 创建StandardScaler对象并拟合数据\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(array)\n",
    "# 对数据进行标准化\n",
    "array = scaler.transform(array)\n",
    "dataset = torch.tensor(array, dtype=torch.float64).float()\n",
    "dataset=dataset.unsqueeze(1)\n",
    "print(dataset.shape)\n",
    "#(batch_size,1,序列长度)\n",
    "\n",
    "batch_size = 128\n",
    "# dataset放到dataloader中\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training model...')\n",
    "# 迭代周期\n",
    "num_epoch = 2000\n",
    "#实例化模型，传入一个数\n",
    "model = Unet1D(dim=32,channels=1).to(device)  \n",
    "model_D = Discriminator(dim=32,channels=1).to(device)  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "optimizerD = torch.optim.Adam(model_D.parameters(), lr=0.0002) \n",
    "loss_function=nn.BCELoss().to(device)  \n",
    "# epoch遍历\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_loss=[]\n",
    "d_loss=[]\n",
    "g_loss=[]\n",
    "for i in range(num_epoch):\n",
    "    # dataloader遍历\n",
    "    epoch_dif_loss=0\n",
    "    epoch_d_loss=0\n",
    "    epoch_g_loss=0\n",
    "    for idx, batch_x in enumerate(dataloader):\n",
    "        #batch_x （128，2）\n",
    "        #得到loss,noise和output\n",
    "        batch_x=batch_x.to(device)\n",
    "        loss,output,x,x_t_minus_1,t = diffusion_loss_fn(model, batch_x, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_steps)\n",
    "        epoch_dif_loss+=loss.item()\n",
    "\n",
    "        #根据预测的噪声去噪\n",
    "        coeff = (betas[t] / one_minus_alphas_bar_sqrt[t]).to(device)\n",
    "        #得到均值\n",
    "        mean = (1 / (1 - betas[t]).sqrt().to(device)) * (x - (coeff * output))\n",
    "        z = torch.randn_like(x).to(device)\n",
    "        sigma_t = betas[t].sqrt().to(device)\n",
    "        #得到去噪的图像\n",
    "        sample = mean + sigma_t * z\n",
    "\n",
    "        t=t.squeeze(-1).squeeze(-1).to(device)\n",
    "        # 优化判别器\n",
    "        optimizerD.zero_grad()\n",
    "        #使用真实数据训练判别器\n",
    "        output_real_noise = model_D(x_t_minus_1.to(device),t)\n",
    "        loss_real=loss_function(output_real_noise,torch.ones_like(output_real_noise).to(device))\n",
    "        loss_real.backward()\n",
    "        #使用output训练判别器\n",
    "        output_fake_noise = model_D(sample.detach().to(device),t)\n",
    "        loss_fake=loss_function(output_fake_noise,torch.zeros_like(output_fake_noise).to(device))\n",
    "        loss_fake.backward()\n",
    "        epoch_d_loss+=(loss_fake.item()+loss_real.item())\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 优化生成器difussion\n",
    "        optimizer.zero_grad()\n",
    "        output_fake_noise = model_D(sample.to(device),t)\n",
    "        loss_fake=loss_function(output_fake_noise,torch.ones_like(output_fake_noise).to(device))\n",
    "        epoch_g_loss+=loss_fake.item()\n",
    "        loss.backward(retain_graph=True)\n",
    "        loss_fake.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_dif_loss=epoch_dif_loss/len(dataloader)\n",
    "    epoch_d_loss=epoch_d_loss/len(dataloader)\n",
    "    epoch_g_loss=epoch_g_loss/len(dataloader)\n",
    "    dif_loss.append(epoch_dif_loss)\n",
    "    d_loss.append(epoch_d_loss)\n",
    "    g_loss.append(epoch_g_loss)\n",
    "    #每100步打印效果\n",
    "    if (i % 20 == 0):\n",
    "        print(i,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dif_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm==False:\n",
    "    torch.save(model.state_dict(),'./'+pad_pattern+'/difussion_gan-difussion{}.pth'.format(num_steps))\n",
    "    torch.save(model_D.state_dict(),'./'+pad_pattern+'/difussion_gan-discriminator{}.pth'.format(num_steps))\n",
    "else:\n",
    "    torch.save(model.state_dict(),'./'+pad_pattern+'/difussion_gan-difussion_norm{}.pth'.format(num_steps))\n",
    "    torch.save(model_D.state_dict(),'./'+pad_pattern+'/difussion_gan-discriminator_norm{}.pth'.format(num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm==False:\n",
    "    model.load_state_dict(torch.load('./'+pad_pattern+'/difussion_gan-difussion{}.pth'.format(num_steps)))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('./'+pad_pattern+'/difussion_gan-difussion_norm{}.pth'.format(num_steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#统计采样时间\n",
    "start=time.time()\n",
    "with torch.no_grad():\n",
    "    x_seq = p_sample_loop(model, [500,1,56], num_steps, betas, one_minus_alphas_bar_sqrt,'cpu')\n",
    "    x_seq[-1].shape\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,51,10):\n",
    "    print(i)\n",
    "    x=x_seq[i].detach().squeeze(1)\n",
    "    x=scaler.inverse_transform(x)\n",
    "    x1=torch.tensor(x,dtype=torch.float64).float()\n",
    "\n",
    "\n",
    "    plt.plot(x1[0])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('C:/Users/45070/Desktop/图片/r_{}.png'.format(i), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(x_seq[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_seq=x_seq[-1].detach().squeeze(1)\n",
    "x=scaler.inverse_transform(x_seq)\n",
    "np.shape(x)\n",
    "x1=torch.tensor(x,dtype=torch.float64).float()\n",
    "\n",
    "plt.plot(x[:].transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=11\n",
    "plt.plot(x1[n])\n",
    "print(x1[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalute import mmd\n",
    "\n",
    "if norm==False:\n",
    "    y = pd.read_csv('./data/'+pad_pattern+'/generate.csv')\n",
    "else:\n",
    "    y = pd.read_csv('./data/'+pad_pattern+'/generate_norm.csv')\n",
    "y = np.array(y)\n",
    "y=y[:500]\n",
    "y=torch.tensor(y,dtype=torch.float64).float()\n",
    "mmd(x1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "distance, path = fastdtw(x1, y, dist=euclidean)\n",
    "distance/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "swd=0\n",
    "for i in range(500):\n",
    "    swd+=scipy.stats.wasserstein_distance(x1[i], y[i])\n",
    "swd/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import dtw\n",
    "l2_norm = lambda x, y: (x - y) ** 2\n",
    "manhattan_distance = lambda x, y: np.abs(x - y)\n",
    "\n",
    "dist, cost_matrix, acc_cost_matrix, path = dtw(x1[8], y[0], dist=l2_norm)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_seq = p_sample_loop(model, [20000,1,56], num_steps, betas, one_minus_alphas_bar_sqrt,'cpu')\n",
    "x_seq=x_seq[-1].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq=x_seq.squeeze(1)\n",
    "x=scaler.inverse_transform(x_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm==False:\n",
    "    x=np.concatenate((x,np.ones((20000,1))),axis=1)\n",
    "else:\n",
    "    x=np.concatenate((x,np.zeros((20000,1))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(x)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm==False:\n",
    "    dataframe.to_csv('./data/'+pad_pattern+'/diffusion.csv',index=False)\n",
    "else:\n",
    "    dataframe.to_csv('./data/'+pad_pattern+'/diffusion_norm.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
